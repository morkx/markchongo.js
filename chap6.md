# An empirical study of the robustness of energy-aware schedulers

Nowadays, energy efficiency is a major concern when operating clusters, datacenters, and grid/cloud computing infrastructures. From a global perspective, all issues related to energy consumption raise several concerns for the scientific community, including economic, environmental, and system performance (Lee and Zomaya, 2009). 

Energy consumption on computing systems does not only depend on the energy efficiency and features of the hardware, but also on the software used for task planning (Ahmad and Ranka, 2012). Among many different strategies for reducing the energy consumption,energy-aware scheduling techniques have emerged as useful alternatives for accurate planning and lowering the power required for operation (Nesmachnow et al., 2013). Energy reduction techniques are usually based on limiting the computing power of the computing elements. They are in conflict with the system performance, so applying them has an impact on the Quality of Service (QoS) perceived by the user. Multi-objective formulations of the scheduling problem have been formulated to account for the specific features of the trade-off between energy utilization
and performance (Dorronsoro et al., 2010). 

The main trend on the scientific community in energy-aware scheduling is based on optimizing the energy consumption of the computing elements since the processor is the main energy consuming element among the hardware components. The processor also offers the most flexible options for energy management, such as dynamic voltage and frequency scaling (DVFS), dynamic power management, slack sharing and reclamation, and other techniques (Zhu et al., 2003).

Many scheduling algorithms are based on assuming that the time required to perform every task is known in advance, and the planning is performed according to that input information. However, that assumption does not hold true in the case of computational infrastructures, where users submit their jobs to be executed on heterogeneous computing elements. Accurately predicting the execution time for individual tasks is a very hard problem, mainly because the actual execution time depends on many factors including the hardware features, communications and delays due to infrastructure and parallel execution, resource availability, among others. Estimation models using task profiling and benchmarking have been proposed since the early 1990â€™s (Ghafoor and Yang, 1993; Kafil and Ahmad, 1998), but they rely on specific hardware features and computing models that are not fully reasonable for nowadays clusters and distributed computing infrastructures. Furthermore, current models for predicting the energy consumption do include some unrealistic approximations about the power utilization, especially in the case of complex multicore servers (Nesmachnow et al., 2013).

This work presents an empirical evaluation of energy-aware schedulers in heterogeneous computing (HC) scenarios that consider uncertainties in both the execution time of tasks and the energy consumption for a given computing infrastructure. We propose three variants of each of the best energy-aware list scheduling techniques proposed in our previous work (Nesmachnow et al., 2013). Then, we analyze their behavior when addressing specific instances of the energy-aware scheduling problem in multicore HC systems, accounting for realistic errors in the estimation of the execution time of tasks, and specific deviations in the power consumption calculation when using a standard energy model for computing systems.

The main contribution of this work consists in proposing novel scheduling algorithms and reporting their experimental evaluation performed over realistic workloads and scenarios, validated by in-situ measurements using a power distribution unit. The empirical results demonstrate that error in real-world scenarios have a significant impact on the accuracy of the scheduling algorithms. Different scheduling approaches were evaluated, and the online approach showed improvements of up to 32% in computing performance and up to 18% in energy consumption over the offline approach using the same scheduling algorithm.
